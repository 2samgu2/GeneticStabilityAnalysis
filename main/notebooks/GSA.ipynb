{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSA - Genetic Stability Analyzer\n",
    "The GSA is a program used to test various machine learning algorithms used for gene expression classification.  This notebook describes the implementation in detail and how to run.  For pure python files see the `main/Python` directory.  \n",
    "\n",
    "Gene expression classification is a common technique used to determine classes of gene expressions (e.g. whether an expression is cancerous or not).  Various classifiers can be used, with a few  listed here:\n",
    "\n",
    " 1. [K-nearest Neighbors](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)\n",
    " 2. [Suport Vector Machine](https://en.wikipedia.org/wiki/Support_vector_machine#Linear_SVM)\n",
    " 3. [Random Forest](https://en.wikipedia.org/wiki/Random_forest)\n",
    " 4. [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    " 5. [Network-based](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4214593/)\n",
    " \n",
    "A question of note for all classifiers is how accurate are they when the gene expression data is perturbed.  At what point will perturbed gene expression data be unable to be classified accurately?  This program attempts to answer this question for each of the classifiers listed above.  It can be extended with more classifiers and perturbation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "Must be pre-installed.  It is recommended to use a [virtual environment](https://docs.python.org/3/tutorial/venv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "from typing import Optional\n",
    "from random import sample, choice, uniform\n",
    "from os import path, getcwd, makedirs\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from math import sqrt, floor\n",
    "from sklearn import svm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from matplotlib.pyplot import savefig, subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and Classes\n",
    "This section defines all classes and methods used.  The methods and classes for each .py file found in `main/Python` are described here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBC.py\n",
    "The NBC.py file contains an implmentation of the Network-based Classifier described by [Ahmet Ay et al](http://journals.sagepub.com/doi/abs/10.4137/CIN.S14025).  Two classes are used: `Model` and `NetworkBasedClassifier`.\n",
    "\n",
    "Briefly, when the classifier is fit, a model is constructed for each class of the training data.  The model consists of a system of equations for each gene expression, derived from the gene's mostly closely correlated neighbors.  The equation for each gene takes the form:\n",
    "\n",
    "\\begin{equation*}\n",
    "f_v^k = \\sum \\nolimits_{u \\in V-v} (\\alpha_{vu} S[u] )+ c_v\n",
    "\\end{equation*}\n",
    "\n",
    "where $f_v^k$ is the function that returns a theoretical gene expression level of gene $v$ if it fell in class $k$. The coefficients and constant, $\\alpha_{vu}$ and $c_v$ respectively, are precomputed from the training data. In this way, given a sample $S$, we can calculate the theoretical expression level of a gene from its neighbors, $S[u]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"The model constructed for a given class\"\"\"\n",
    "\n",
    "    def __init__(self, X, label, epsilon=0.8):\n",
    "        \"\"\"Initializes the model for a given class.\n",
    "\n",
    "        :param X: Training data for model. If array or matrix, shape [n_samples, n_features].\n",
    "        :param label: Class label for the data.\n",
    "        :param epsilon: Correlation cutoff value.\n",
    "        \"\"\"\n",
    "        self._label = label\n",
    "        self.X = np.array(X)\n",
    "\n",
    "        correlations = np.corrcoef(self.X, y=None, rowvar=False)\n",
    "\n",
    "        # Note: the mask is the graph.\n",
    "        self.mask = (np.absolute(correlations) > epsilon)\n",
    "        print(np.sum(self.mask[0]))\n",
    "\n",
    "        pool = Pool(processes=cpu_count())\n",
    "        self.coefficients = pool.starmap(self.solver,\n",
    "                                         [(gene, self.mask[gene], self.X) for gene in range(len(correlations))])\n",
    "        pool.terminate()\n",
    "\n",
    "        self.coefficients = np.array(self.coefficients)\n",
    "        print(\"NBC Model constructed.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def solver(gene, mask, X):\n",
    "        \"\"\"Uses least-square solver to compute coefficients for Ax=b, where\n",
    "        A is an equation list created from the neighbors of a gene and b is\n",
    "        the value of the gene.\n",
    "\n",
    "        :param gene: The index of the gene to be solved for.\n",
    "        :param mask: The correlation mask for the gene.\n",
    "        :param X: The training samples.\n",
    "        :return: The coefficients of the equation (x) in Ax=b\n",
    "        \"\"\"\n",
    "        A = []\n",
    "        b = []\n",
    "        for sample in X:\n",
    "            neighbors = [sample[neighbor] if (mask[neighbor] and (gene != neighbor))\n",
    "                         else 0\n",
    "                         for neighbor in range(len(mask))]\n",
    "            neighbors.append(1)\n",
    "            A.append(neighbors)\n",
    "            b.append(sample[gene])\n",
    "        A = np.array(A)\n",
    "        b = np.array(b)\n",
    "        x = lsqr(A, b)[0]\n",
    "        return x.tolist()\n",
    "\n",
    "    def expression(self, sample):\n",
    "        \"\"\"Returns a hypothetical expression level for a given sample.\n",
    "\n",
    "        :param sample: Test sample\n",
    "        :return: The hypothetical expression level of a given sample.\n",
    "        \"\"\"\n",
    "        expression = []\n",
    "        for gene in range(len(self.coefficients)):\n",
    "            level = 0  # the expression level of a gene\n",
    "            for neighbor in range(len(self.mask) - 1):\n",
    "                level += self.coefficients[gene][neighbor] * sample[neighbor]\n",
    "            level += self.coefficients[gene][len(self.mask)]\n",
    "            expression.append(level)\n",
    "        return np.array(expression)\n",
    "\n",
    "    def label(self):\n",
    "        \"\"\"Returns the class label of the model.\n",
    "\n",
    "        :return: The class label of the model.\n",
    "        \"\"\"\n",
    "        return self._label\n",
    "\n",
    "\n",
    "class NetworkBasedClassifier:\n",
    "    \"\"\"Classifier implementing the Network-based Classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=0.8):\n",
    "        \"\"\"Initializes the classifier.\n",
    "\n",
    "        :param epsilon: epsilon value correlation cutoff.\n",
    "        \"\"\"\n",
    "        self.models = []\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model using X as training data and y as target values.\n",
    "\n",
    "        :param X: Training data. If array or matrix, shape [n_samples, n_features].\n",
    "        :param y: Target values of shape = [n_samples]\n",
    "        \"\"\"\n",
    "        self.models = []\n",
    "        y = np.array(y)\n",
    "        X = np.array(X)\n",
    "        for label in Counter(y):\n",
    "            a_class = np.where(y == label)\n",
    "            self.models.append(Model([X[i] for i in a_class[0]], label, self.epsilon))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the class labels for the provided data.\n",
    "\n",
    "        :param X: Test samples.\n",
    "        :return: Class labels for each data sample.\n",
    "        \"\"\"\n",
    "        pool = Pool(processes=cpu_count())\n",
    "        classifications = pool.map(self.classification, [sample for sample in X])\n",
    "        pool.terminate()\n",
    "        return classifications\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Returns the mean accuracy on the given test data and labels.\n",
    "\n",
    "        :param X: Test samples.\n",
    "        :param y: True labels for X.\n",
    "        :return: Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        X = np.array(X)\n",
    "        correct = np.asarray(self.predict(X) == y)\n",
    "        return np.sum(correct) / correct.shape[0]\n",
    "\n",
    "    def classification(self, sample):\n",
    "        \"\"\"Returns the classification of the sample.\n",
    "\n",
    "        :param sample: Test sample\n",
    "        :return: The class label of the sample.\n",
    "        \"\"\"\n",
    "        errors = []\n",
    "        for model in self.models:\n",
    "            error = sqrt(mean_squared_error(sample, model.expression(sample)))\n",
    "            errors.append(error)\n",
    "        min_index = errors.index(min(errors))\n",
    "        return self.models[min_index].label()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimatory.py\n",
    "The estimator.py file holds a wrapper class, `Estimator`, for classifiers used in the stability analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator:\n",
    "    \"\"\"Describes the classifier chooser.\"\"\"\n",
    "\n",
    "    # Classifiers included:\n",
    "    NBC = 0\n",
    "    KNN = 1\n",
    "    SVM = 2\n",
    "    RF = 3\n",
    "    NB = 4\n",
    "    \n",
    "    def __init__(self, _type, epsilon=0.8, k=1):\n",
    "        \"\"\"Initializes the classifier type.\n",
    "\n",
    "        :param _type: The type of classifier to initialize.\n",
    "        :param epsilon: Used in NBC (See nbc.py for more details).\n",
    "        :param k: Used in KNeighborsClassifier (See documentation for more details).\n",
    "        \"\"\"\n",
    "        self._type = _type\n",
    "\n",
    "        # create the classifier\n",
    "        if self.type == Estimator.NBC:\n",
    "            self._classifier = NetworkBasedClassifier(epsilon)\n",
    "            self._name = \"NBC\"\n",
    "        elif self.type == Estimator.KNN:\n",
    "            self._classifier = KNeighborsClassifier(k)\n",
    "            self._name = \"KNN\"\n",
    "        elif self.type == Estimator.SVM:\n",
    "            self._classifier = svm.LinearSVC()\n",
    "            self._name = \"SVM\"\n",
    "        elif self.type == Estimator.RF:\n",
    "            self._classifier = RandomForestClassifier()\n",
    "            self._name = \"RF\"\n",
    "        elif self.type == Estimator.NB:\n",
    "            self._classifier = GaussianNB()\n",
    "            self._name = \"NB\"\n",
    "    \n",
    "    @property\n",
    "    def type(self):\n",
    "        \"\"\"Returns the type of the classifier.\n",
    "\n",
    "        :return: The type of the classifier\n",
    "        \"\"\"\n",
    "        return self._type\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"Returns the name of the classifier.\n",
    "\n",
    "        :return: The string name of the classifier.\n",
    "        \"\"\"\n",
    "        return self._name\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model using X as training data and y as target values.\n",
    "\n",
    "        :param X: Training data. If array or matrix, shape [n_samples, n_features].\n",
    "        :param y: Target values of shape = [n_samples]\n",
    "        \"\"\"\n",
    "        self._classifier.fit(X, y)\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Returns the mean accuracy on the given test data and labels.\n",
    "\n",
    "        :param X: Test samples\n",
    "        :param y: True labels for X\n",
    "        :return: Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        return self._classifier.score(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the class labels for the provided data.\n",
    "\n",
    "        :param X: Test samples.\n",
    "        :return: lass labels for each data sample.\n",
    "        \"\"\"\n",
    "        return self._classifier.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter.py\n",
    "The Alter.py file contains a class for creating an alteration strategy, `AlterStrategy`.  These methods are used to alter expressions and calculate accuracies of classifiers under the alteration condition.  There are currently four methods to alter expressions:\n",
    "\n",
    "1. All - Alters all genes by some percent amount. Note that this actually selects a random expression level between low and high, with low and high increasing as percent increases.\n",
    "2. Subset - Selects a subset of the genes using chi2 values and alters them between min and max gene level.\n",
    "3. Random Subset - Selects a random subset of genes and alters them between min and max gene level.\n",
    "4. Greedy - Uses a greedy strategy to select the top k genes that will produce the smallest accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: cross-validation is different from the normal type in that the estimator is fit to correct data while the score is derived from altered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlterStrategy:\n",
    "    \"\"\"Describes the alteration strategy used.\"\"\"\n",
    "\n",
    "    # Alter strategies included:\n",
    "    ALL = 0\n",
    "    SUB = 1\n",
    "    RAND_SUB = 2\n",
    "    GREEDY = 3\n",
    "\n",
    "    def __init__(self, strategy, estimator: Estimator = None,\n",
    "                 X=None, y=None, path=None):\n",
    "        \"\"\"Initializes an alter strategy.\n",
    "\n",
    "        :param strategy: The strategy to be initialized.  e.g. AlterStrategy.ALL\n",
    "        :param estimator: The estimator (aka classifier) tested by the strategy.\n",
    "        :param X: The samples. [n_samples, n_features]\n",
    "        :param y: The classes (aka labels for the samples. [n_samples]\n",
    "        :param path: The path to a folder to save files to.\n",
    "        \"\"\"\n",
    "        self._type = strategy\n",
    "        self.estimator = estimator\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.path = path\n",
    "\n",
    "        if self.type == AlterStrategy.ALL:\n",
    "            self._name = \"ALL\"\n",
    "        elif self.type == AlterStrategy.SUB:\n",
    "            self._name = \"SUB\"\n",
    "        elif self.type == AlterStrategy.RAND_SUB:\n",
    "            self._name = \"RAND_SUB\"\n",
    "        elif self.type == AlterStrategy.GREEDY:\n",
    "            self._name = \"GREEDY\"\n",
    "            filename = '{}greedyRank.npy'.format(self.estimator.name)\n",
    "            self.greedy_path = os.path.join(path, filename)\n",
    "            # if a green rank doesn't exist, create one\n",
    "            if not os.path.exists(self.greedy_path):\n",
    "                print(\"GREEDY RANK INITIALIZER - THIS CAN TAKE A WHILE.\")\n",
    "                self.estimator.fit(X, y)\n",
    "                to_choose = list(range(X.shape[1]))\n",
    "                chosen = []\n",
    "                for i in range(X.shape[1]):\n",
    "                    accuracies = []\n",
    "                    for idx in to_choose:\n",
    "                        accuracies.append(self.accuracy(X, y, chosen, idx, self.estimator))\n",
    "                    a = [x for _, x in sorted(zip(accuracies, to_choose))]\n",
    "                    chosen.append(a[0])\n",
    "                    to_choose.remove(a[0])\n",
    "                np.save(self.greedy_path, chosen)\n",
    "\n",
    "    @property\n",
    "    def type(self):\n",
    "        \"\"\"Returns the type of the alteration strategy.\n",
    "\n",
    "        :return: The type of the alteration strategy\n",
    "        \"\"\"\n",
    "        return self._type\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"Returns the name of the alteration strategy.\n",
    "\n",
    "        :return: The string name of the alteration strategy.\n",
    "        \"\"\"\n",
    "        return self._name\n",
    "\n",
    "    @staticmethod\n",
    "    def accuracy(X, y, chosen, idx_to_change, estimator: Estimator = None):\n",
    "        \"\"\"\n",
    "\n",
    "        :param X: Test samples.\n",
    "        :param y: True labels for X.\n",
    "        :param chosen: Indices chosen so far\n",
    "        :param idx_to_change: The index to change and test.\n",
    "        :param estimator: The estimator (aka classifier) used to score the change.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for x in X:\n",
    "            alt = np.copy(x)\n",
    "            # alter prev chosen\n",
    "            for i in chosen:\n",
    "                alt[i] = 0\n",
    "            # alter new gene\n",
    "            alt[idx_to_change] = 0\n",
    "            result.append(alt)\n",
    "        result = np.array(result)\n",
    "        return estimator.score(result, y)\n",
    "\n",
    "    def alter(self, percent, X):\n",
    "        \"\"\"Alters a percent of the genes in the Test samples by the alteration strategy.\n",
    "        Note: Because genes are already ordered by chi2 rank in the main program,\n",
    "         we can choose top k to alter for the SUB strategy.\n",
    "\n",
    "        :param percent: The percent of the subset to select from X\n",
    "        :param X: Test samples.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        high = np.amax(self.X)\n",
    "        low = np.amin(self.X)\n",
    "        result = []\n",
    "        k = floor(X[0].size * percent)\n",
    "        if k <= 0:\n",
    "            return X\n",
    "        else:\n",
    "            indices = []\n",
    "            if self.type == AlterStrategy.RAND_SUB:\n",
    "                indices = sample(range(X[0].size), k)\n",
    "            elif self.type == AlterStrategy.SUB:\n",
    "                indices = list(range(k))\n",
    "            elif self.type == AlterStrategy.GREEDY:\n",
    "                indices = np.load(self.greedy_path)[0:k:1]\n",
    "            elif self.type == AlterStrategy.ALL:\n",
    "                indices = list(range(X[0].size))\n",
    "            for x in X:\n",
    "                alt = np.copy(x)\n",
    "                for i in indices:\n",
    "                    if self.type == AlterStrategy.ALL:\n",
    "                        offset = alt[i] * percent\n",
    "                        low = alt[i] - offset\n",
    "                        high = alt[i] + offset\n",
    "                        alt[i] = choice([low, high])\n",
    "                    else:\n",
    "                        alt[i] = uniform(low, high)\n",
    "                result.append(alt)\n",
    "            return np.array(result)\n",
    "\n",
    "    def cross_validate(self, percent=0, n_splits=10):\n",
    "        \"\"\"Performs cross validation of the alteration strategy used for a given\n",
    "        percentage of genes in the test samples.\n",
    "\n",
    "        :param percent: The percentage of genes to alter.\n",
    "        :param n_splits: The number of folds.\n",
    "        :return: The scores for a given percentage change.\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        skf = StratifiedKFold(n_splits)\n",
    "        for train_index, test_index in skf.split(self.X, self.y):\n",
    "            self.estimator.fit(self.X[train_index], self.y[train_index])\n",
    "            accuracy = self.estimator.score(\n",
    "                self.alter(percent, self.X[test_index]), self.y[test_index])\n",
    "            scores.append(accuracy)\n",
    "        return np.array(scores)\n",
    "\n",
    "    def get_accuracies(self, step=0.05):\n",
    "        \"\"\" Calculates the accuracies for [0,1] at increments of step.  This\n",
    "        acts as a percentage of the genes to change from 0 to 100%.\n",
    "\n",
    "        :param step: The step size for the accuracies.\n",
    "        :return: The accuracies over all steps from 0 to 1\n",
    "        \"\"\"\n",
    "        percents = np.arange(0, 1.01, step)\n",
    "        accuracies = []\n",
    "        deviations = []\n",
    "        for percent in percents:\n",
    "            scores = self.cross_validate(percent)\n",
    "            accuracies.append(scores.mean())\n",
    "            deviations.append(scores.std())\n",
    "        accuracies = np.array(accuracies)\n",
    "        deviations = np.array(deviations)\n",
    "        result = np.column_stack((percents, accuracies, deviations))\n",
    "        filename = '{}_{}_result.npy'.format(self.estimator.name, self.name)\n",
    "        np.save(os.path.join(self.path, filename), result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers\n",
    "In order to speed up processing time when running classification algorithms, it is often useful to choose only the \"best\" features (aka genes) to use.  There are various algorithms available to choose features, however here we use Chi2 to select the $k$ best features.  A good $k$ is important to prevent overfitting or underfitting of the models.  In practice, $k$ usually ranges from 50 to 300 for most genetic studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this is in alter.py because at a future date it may be integrated.  Be aware that the selection is ranked by chi2 score, and this order is used by the SUB alteration strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_k_best(k, X, y):  \n",
    "    \"\"\"Selects the top k features, returning their indices in chi2 rank order.\n",
    "\n",
    "    :param k: Number of top features to select.\n",
    "    :param X: The training input samples.\n",
    "    :param y: The target values (class labels in classification)\n",
    "    :return: Ranked indices by score.\n",
    "    \"\"\"\n",
    "    b = SelectKBest(chi2, k).fit(X, y)\n",
    "    a = b.get_support(indices = True)\n",
    "    a = [x for _,x in sorted(zip(b.scores_[a],a),reverse=True)]\n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program\n",
    "###### Enter the series and feature_size to use\n",
    "Must be all upper case. e.g. `\"GSE27562\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = \"GSE19804\"\n",
    "feature_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Classes and Expressions\n",
    "Load original data and select the features. This assumes SIT and a custome GSE script have been run to import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notebook_dir = getcwd();\n",
    "main_dir = path.dirname(path.dirname(notebook_dir))\n",
    "load_path = path.join(main_dir, \"GSE\", series)\n",
    "gsa_path = path.join(main_dir,\"GSA\", series, str(feature_size))\n",
    "if not path.exists(gsa_path):\n",
    "    makedirs(gsa_path)\n",
    "\n",
    "y = np.loadtxt(path.join(load_path, \"classes.txt\"), dtype=np.str, delimiter=\"\\t\")\n",
    "X = np.loadtxt(path.join(load_path, \"expressions.txt\"), delimiter=\"\\t\")\n",
    "\n",
    "a = select_k_best(feature_size, X, y)\n",
    "X = X[:, a]\n",
    "\n",
    "np.save(path.join(gsa_path, \"expressions.npy\"), X)\n",
    "np.save(path.join(gsa_path, \"classses.npy\"), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcualte stability of classifiers using various alter strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimators = [Estimator(Estimator.KNN),\n",
    "              Estimator(Estimator.SVM),\n",
    "              Estimator(Estimator.RF),\n",
    "              Estimator(Estimator.NB),\n",
    "              Estimator(Estimator.NBC)]\n",
    "\n",
    "for estimator in estimators:\n",
    "    strategies = [AlterStrategy(AlterStrategy.ALL, estimator, X, y, gsa_path),\n",
    "                  AlterStrategy(AlterStrategy.SUB, estimator, X, y, gsa_path),\n",
    "                  AlterStrategy(AlterStrategy.RAND_SUB, estimator, X, y, gsa_path),\n",
    "                  AlterStrategy(AlterStrategy.GREEDY, estimator, X, y, gsa_path)]\n",
    "    for strategy in strategies:\n",
    "        result = strategy.get_accuracies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Result\n",
    "This code demonstrates one way to plot results from the GSA program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = \"GSE19804\"\n",
    "feature_size = 50\n",
    "\n",
    "notebook_dir = getcwd();\n",
    "main_dir = path.dirname(path.dirname(notebook_dir))\n",
    "load_path = path.join(main_dir, \"GSE\", series)\n",
    "gsa_path = path.join(main_dir,\"GSA\", series, str(feature_size))\n",
    "\n",
    "classifiers = ['KNN', 'SVM', 'RF', 'NB', 'NBC']\n",
    "strategies = ['ALL', 'SUB', 'RAND_SUB', 'GREEDY']\n",
    "names = ['All', 'Chi2 Subset', 'Random Subset', 'Greedy']\n",
    "\n",
    "fig, axs = subplots(1, len(strategies), figsize = (16,4), sharey = True)\n",
    "\n",
    "i = 0\n",
    "for strategy in strategies:\n",
    "    for classifier in classifiers:\n",
    "        data = np.load(path.join(gsa_path, \"{}_{}_result.npy\".format(classifier, strategy)))\n",
    "        data = list(zip(*list(data)))\n",
    "        axs[i].plot(np.arange(0,101,5), np.array(data[1])*100, label = classifier)\n",
    "        axs[i].set_xlim(0, 100)\n",
    "        axs[i].set_title(names[i])\n",
    "        axs[i].set_xlabel(\"Altered\")\n",
    "        vals = axs[i].get_xticks()\n",
    "        axs[i].set_xticklabels(['{}%'.format(int(x)) for x in vals])\n",
    "    handles, labels = axs[i].get_legend_handles_labels()  \n",
    "    i = i + 1\n",
    "\n",
    "axs[0].set_ylabel(\"Accuracy\")\n",
    "values = axs[0].get_yticks()\n",
    "axs[0].set_yticklabels(['{}%'.format(int(x)) for x in values])\n",
    "\n",
    "fig.legend(handles, labels, loc=3, bbox_to_anchor=(0.35, 1.0, 0.3, 0), \n",
    "           ncol=len(classifiers), mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "savefig('results.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
