{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSA - Genetic Stability Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed up processing time when running classification algorithms, it is often useful to choose only the most \"best\" genes to use.  There are various algorithms available to choose genes, however here we use Chi2 Select K best.  K is how many genes you wish to use for testing stability.  More genese is usually better, however again in order to speed up processing time we limit the number of genes used.  This program allows you to set a min and max number of genes and an interval.  This will in turn setup numpy arrays with class and the select number of genes for further processing by FASTR and FASTrand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "Must be pre-installed.  Recommended to use virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terek/.virtualenvs/py370/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import sample, choice, uniform\n",
    "from os import path, getcwd, makedirs\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from math import sqrt, floor\n",
    "from sklearn import svm\n",
    "import multiprocessing as mp\n",
    "from enum import Enum\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and Classes\n",
    "This section defines all classes and methods used.  The corresponding methods and classes for each .py file found in `main/Python` are described here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBC.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NBC.py file contains two classes: Model and NBC.  The Network-based supervised classification technique (NBC) is described in [Ahmet Ay et al](http://journals.sagepub.com/doi/abs/10.4137/CIN.S14025).  Briefly, for each gene, a model is constructed from the gene's neighbors.  The model is a function of the form:\n",
    "\n",
    "gene_expressipn @ g = neigh1X + neigh2X +....neighNx + C\n",
    "\n",
    "The set of expressions for all genes creates the expressio nmodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"Describes the model class.\"\"\"\n",
    "\n",
    "    def __init__(self, samples, eps, class_label):\n",
    "        \"\"\"Initialize the model class.\n",
    "\n",
    "        Args:\n",
    "            samples: training samples of size [samples, genes].\n",
    "            eps: epsilon value for correlation cutoff.\n",
    "            class_label: classification label.\n",
    "        \"\"\"\n",
    "\n",
    "        self.class_label = class_label\n",
    "        self.samples = np.array(samples)\n",
    "        self.eps = eps\n",
    "\n",
    "        # columns are variables, rows are samples\n",
    "        self.correlation = np.corrcoef(self.samples, y=None, rowvar=False)\n",
    "\n",
    "        # note that the mask is actually the graph\n",
    "        self.mask = (np.absolute(self.correlation) > self.eps)\n",
    "\n",
    "        # the coefficients associated with the system of equation: Ax=b,\n",
    "        # where A is an equation list created from the neighbors of gene\n",
    "        # n and b is the value of gene n.\n",
    "        self.geneFuncMasks = []  # these are the coefficients in Ax=b\n",
    "        pool = mp.Pool(processes = mp.cpu_count())\n",
    "        self.geneFuncMasks = pool.map(self.helper,[(gene) for gene in range(len(self.correlation))])\n",
    "        pool.terminate()\n",
    "#        for gene in range(len(self.correlation)):\n",
    "#            currMask = self.mask[gene]\n",
    "#            setOfNeighbors = []\n",
    "#            solutions = []\n",
    "#            for sample in self.samples:\n",
    "#                neighbors = [sample[neighbor] if (currMask[neighbor] and (gene != neighbor))\n",
    "#                             else 0 for neighbor in range(len(currMask))]\n",
    "#                neighbors.append(1)\n",
    "#                setOfNeighbors.append(neighbors)\n",
    "#                solutions.append(sample[gene])\n",
    "#            coeff = self.solver(setOfNeighbors, solutions, 2)\n",
    "#            self.geneFuncMasks.append(coeff.tolist())\n",
    "\n",
    "        self.coefficients = np.array(self.geneFuncMasks)\n",
    "        \n",
    "    def helper(self, gene):\n",
    "        currMask = self.mask[gene]\n",
    "        setOfNeighbors = []\n",
    "        solutions = []\n",
    "        for sample in self.samples:\n",
    "            neighbors = [sample[neighbor] if (currMask[neighbor] and (gene != neighbor))\n",
    "                         else 0 for neighbor in range(len(currMask))]\n",
    "            neighbors.append(1)\n",
    "            setOfNeighbors.append(neighbors)\n",
    "            solutions.append(sample[gene])\n",
    "        coeff = self.solver(setOfNeighbors, solutions, 2)\n",
    "        return coeff.tolist()\n",
    "        #self.geneFuncMasks.append(coeff.tolist())        \n",
    "\n",
    "    def solver(self, neighbors, sols, choice):\n",
    "        # Use lsqr to solve Ax=b\n",
    "        A = np.array(neighbors)\n",
    "        b = np.array(sols)\n",
    "        x = lsqr(A, b)[0]\n",
    "        return x\n",
    "\n",
    "    def expression(self, sample):\n",
    "        \"\"\"Given a sample, return the hypothetical expression.\n",
    "\n",
    "        Args:\n",
    "            sample: the sample whose hypothetical expression we wish to\n",
    "            calculate\n",
    "        Returns:\n",
    "            expr: A list with the expression values of size number of genes.\n",
    "        \"\"\"\n",
    "        expression = []\n",
    "        for gene in range(len(self.coefficients)):\n",
    "            geneVal = 0\n",
    "            for neighbor in range(len(self.mask)-1):\n",
    "                geneVal += self.coefficients[gene][neighbor] * sample[neighbor]\n",
    "            geneVal += self.coefficients[gene][len(self.mask)]\n",
    "            expression.append(geneVal)\n",
    "        return np.array(expression)\n",
    "\n",
    "    def label (self):\n",
    "        \"\"\"Return the classification label of this model.\"\"\"\n",
    "        return self.class_label\n",
    "\n",
    "\n",
    "class NetworkBasedClassifier:\n",
    "    \"\"\"Describes the NBClassifier class.\"\"\"\n",
    "\n",
    "    def __init__(self, epsilon):\n",
    "        \"\"\"Initialize a NBF classifier.\n",
    "\n",
    "        Args:\n",
    "            eps: epsilon value\n",
    "        \"\"\"\n",
    "        self.models = []\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the data with classes to create class models.\n",
    "\n",
    "        Fits the data [num_samples, num_genes] with classifications\n",
    "        [num_samples] to the model.  Creates as many models as classes.\n",
    "\n",
    "        Args:\n",
    "            X: the data we wish to train the classifier on\n",
    "            y: the classifications associated with the samples\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        X = np.array(X)\n",
    "        for key in Counter(y):\n",
    "            a_class = np.where(y == key)\n",
    "            self.models.append(Model([X[i] for i in a_class[0]], self.epsilon, key))\n",
    "\n",
    "            \n",
    "    def score(self, X, y):\n",
    "        \"\"\"Scores the classifications of a given set of samples (X) according to their\n",
    "        actual clsssifications (y).\n",
    "\n",
    "        Must fit the classifier before this method is called.\n",
    "\n",
    "        Args:\n",
    "            samples: the samples we wish to predict classification for.\n",
    "\n",
    "        Returns:\n",
    "            accuracy: the classification accuracy\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        X = np.array(X)\n",
    "        predicted = self.predict(X)        \n",
    "        correct = np.asarray(predicted == y)\n",
    "        return np.sum(correct)/correct.shape[0]        \n",
    " \n",
    "    def getClassification(self, sample):\n",
    "        RMSEs = []\n",
    "        for model in self.models:\n",
    "            rmse = sqrt( mean_squared_error(sample, model.expression(sample)))\n",
    "            RMSEs.append(rmse)\n",
    "        min_index = RMSEs.index(min(RMSEs))\n",
    "        return self.models[min_index].label()        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the classification of a sample.\n",
    "\n",
    "        Must fit the classifier before this method is called.\n",
    "\n",
    "        Args:\n",
    "            samples: the samples we wish to predict classification for.\n",
    "\n",
    "        Returns:\n",
    "            classifications: the classifications of the samples.\n",
    "        \"\"\"\n",
    "        classifications = []\n",
    "        pool = mp.Pool(processes = mp.cpu_count())\n",
    "        classifications = pool.map(self.getClassification, [(sample) for sample in X])\n",
    "        pool.terminate()\n",
    "        \n",
    "#        for sample in X:\n",
    "#            RMSEs = []\n",
    "#            for model in self.models:\n",
    "#                rmse = sqrt( mean_squared_error(sample, model.expression(sample)))\n",
    "#                RMSEs.append(rmse)\n",
    "#            min_index = RMSEs.index(min(RMSEs))\n",
    "#            label = self.models[min_index].label()\n",
    "#            classifications.append(label)\n",
    "        return np.array(classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter.py\n",
    "The Alter.py file contains all methods and helper methods used to alter expressions.  There are currently four methods to alter expressions:\n",
    "\n",
    "1) Greedy - uses a greed strategy to select the top k genes that will produce the largest bad accuracy\n",
    "2) All - alters all genes by some percent amount.\n",
    "3) Subset - alters a subset of the genes selected via chi2 value\n",
    "4) RandSubset - alters a subset of the genes selected randomly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlterStrategy:\n",
    "    \"\"\"Describes the alteration strategy used.\"\"\"\n",
    "\n",
    "    # Alter strategies included:\n",
    "    ALL = 0\n",
    "    SUB = 1\n",
    "    RANDSUB = 2\n",
    "    GREEDY = 3\n",
    "    \n",
    "    def __init__(self,\n",
    "                 _type):\n",
    "        self._type = _type\n",
    "        if _type == AlterStrategy.ALL:\n",
    "            self._name = \"ALL\"\n",
    "        elif (_type == AlterStrategy.SUB):\n",
    "            self._name = \"SUB\"\n",
    "        elif (_type == AlterStrategy.RANDSUB):\n",
    "            self._name = \"RANDSUB\"\n",
    "        elif (_type == AlterStrategy.GREEDY):\n",
    "            self._name = \"GREEDY\"\n",
    "    \n",
    "    def getType(self):\n",
    "        return self._type\n",
    "    \n",
    "    def getName(self):\n",
    "        return self._name\n",
    "    \n",
    "    def Accuracy(estimator, X, y, chosen, idx_to_change):\n",
    "        # TODO: run multiple times and return avg accuracy\n",
    "        result = []\n",
    "        for x in X:\n",
    "            alt = np.copy(x)\n",
    "            # alter prev chosen\n",
    "            for i in chosen:\n",
    "                #alt[i] = choice([0, alt[i]*2]) \n",
    "                alt[i] = 0\n",
    "            # alter new gene\n",
    "            #alt[idx_to_change] = choice([0, alt[idx_to_change]*2]) \n",
    "            alt[idx_to_change] = 0\n",
    "            result.append(alt)\n",
    "        result = np.array(result)\n",
    "        return estimator.score(result, y)\n",
    "\n",
    "    '''Static method'''\n",
    "    def RankGreedy(estimator, X, y):\n",
    "        fileName = '{}greedyRank.npy'.format(estimator.getName())\n",
    "        if (path.exists(path.join(gsa_path, fileName))):\n",
    "            return\n",
    "        print(\"GREEDY RANK INITIALIZER - THIS CAN TAKE A WHILE.\")\n",
    "        estimator.fit(X,y)\n",
    "        notChosen = list(range(X.shape[1]))\n",
    "        chosen = []\n",
    "        for i in range(X.shape[1]):\n",
    "            pool = mp.Pool(processes = mp.cpu_count())\n",
    "            accuracy = pool.starmap(AlterStrategy.Accuracy, [(estimator, X, y, chosen, idx) for idx in notChosen])\n",
    "            pool.terminate()\n",
    "            a = [x for _,x in sorted(zip(accuracy, notChosen))]\n",
    "            chosen.append(a[0])\n",
    "            notChosen.remove(a[0])  \n",
    "        np.save(path.join(gsa_path,fileName), chosen)\n",
    "        \n",
    "    def Subset(percent, X):\n",
    "        \"\"\"\n",
    "        B/c genese are already ordered by chi2 rank we can choose top k to alter.\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        idx = floor(X[0].size * percent)\n",
    "        if idx <= 0:\n",
    "            return X\n",
    "        else:\n",
    "            for x in X:\n",
    "                alt = np.copy(x)\n",
    "                for i in range(idx):\n",
    "                    alt[i] = choice([0, alt[i]*2])\n",
    "                result.append(alt)\n",
    "            return np.array(result)\n",
    "\n",
    "    def RandSubset(percent,X):\n",
    "        result = []\n",
    "        k = floor(X[0].size * percent)\n",
    "        if k <= 0:\n",
    "            return X\n",
    "        else:\n",
    "            indices = sample(range(X[0].size),k)\n",
    "            for x in X:\n",
    "                alt = np.copy(x)\n",
    "                for i in indices:\n",
    "                    alt[i] = choice([0, alt[i]*2])\n",
    "                result.append(alt)\n",
    "            return np.array(result)\n",
    "        \n",
    "    def All(percent, X):\n",
    "        print(percent)\n",
    "        result = []\n",
    "        for x in X:\n",
    "            print(x)\n",
    "            alt = []\n",
    "            for gene in x:\n",
    "                _offset = gene * percent\n",
    "                _low = gene - _offset\n",
    "                _high = gene + _offset\n",
    "                alt.append(choice([_low,_high]))\n",
    "            result.append(alt)\n",
    "            print(alt)\n",
    "        return np.array(result)        \n",
    "        \n",
    "    def Greedy(percent, X, estimator):\n",
    "        high = np.amax(X)\n",
    "        low = np.amin(X)\n",
    "        result = []\n",
    "        k = floor(X[0].size * percent)\n",
    "        if k <= 0:\n",
    "            return X        \n",
    "        else:\n",
    "            file = path.join(gsa_path,'{}greedyRank.npy'.format(estimator.getName()))\n",
    "            indices = np.load(file)\n",
    "            for x in X:\n",
    "                alt = np.copy(x)\n",
    "                for i in indices[0:k:1]:\n",
    "                    alt[i] = uniform(low, high)\n",
    "                result.append(alt)\n",
    "            return np.array(result)        \n",
    "        \n",
    "    def Alter(self, percent, X, estimator):\n",
    "        if self._type == AlterStrategy.ALL:\n",
    "            return AlterStrategy.All(percent, X)\n",
    "        elif self._type == AlterStrategy.SUB:\n",
    "            return AlterStrategy.Subset(percent, X)\n",
    "        elif self._type == AlterStrategy.RANDSUB:\n",
    "            return AlterStrategy.RandSubset(percent, X)\n",
    "        elif self._type == AlterStrategy.GREEDY:\n",
    "            return AlterStrategy.Greedy(percent, X, estimator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy is to choose greedily, however because of the random choice from the Accuracy method strategy, different genese may be chose, thus affecting the order in which the rank returns.  In general, the top gene should be the top gene in all cases, but as it progresses the genese can switch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common.py\n",
    "These are files that are helpers for the main program.  They consist of two methods:\n",
    "1) A method to order the K best ranked genes.  This is used in conjunction with Atler.py Subset method.\n",
    "2) A method to cross validate.  This is different than normal cross validation in that the estimator is fit to correct data while the score is derived from altered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectKBestRanked(k, X, y):    \n",
    "    b = SelectKBest(chi2, k).fit(X, y)\n",
    "    a = b.get_support(indices = True)\n",
    "    a = [x for _,x in sorted(zip(b.scores_[a],a),reverse=True)]\n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(estimator, X, y, alterStrat, percent=0, cv=10):\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(cv)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        estimator.fit(X[train_index], y[train_index]) \n",
    "        accuracy = estimator.score(\n",
    "            alterStrat.Alter(percent, X[test_index],estimator),\n",
    "            y[test_index])\n",
    "        scores.append(accuracy)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimatory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator:\n",
    "    \"\"\"Describes the classifier chooser.\"\"\"\n",
    "\n",
    "    # Classifiers included in the chooser\n",
    "    NBC = 0\n",
    "    KNN = 1\n",
    "    SVM = 2\n",
    "    RF = 3\n",
    "    NB = 4\n",
    "    \n",
    "    def __init__(self,\n",
    "                 _type,\n",
    "                 epsilon=0.8,\n",
    "                 neighbors=1):\n",
    "        \"\"\"Initialize a NBF classifier.\n",
    "\n",
    "        Args:\n",
    "            eps: epsilon value\n",
    "        \"\"\"\n",
    "        self._type = _type\n",
    "\n",
    "        # create the classifier\n",
    "        if _type == Estimator.NBC:\n",
    "            self._classifier = NetworkBasedClassifier(epsilon)\n",
    "            self._name = \"NBC\"\n",
    "        elif (_type == Estimator.KNN):\n",
    "            self._classifier = KNeighborsClassifier(neighbors)\n",
    "            self._name = \"KNN\"\n",
    "        elif (_type == Estimator.SVM):\n",
    "            self._classifier = svm.LinearSVC()\n",
    "            self._name = \"SVM\"\n",
    "        elif (_type == Estimator.RF):\n",
    "            self._classifier = RandomForestClassifier()\n",
    "            self._name = \"RF\"\n",
    "        elif (_type == Estimator.NB):\n",
    "            self._classifier = GaussianNB()\n",
    "            self._name = \"NB\"\n",
    "    \n",
    "    def getType(self):\n",
    "        return self._type\n",
    "    \n",
    "    def getName(self):\n",
    "        return self._name\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._classifier.fit(X,y)\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return self._classifier.score(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self._classifier.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Enter the series and feature_size to use\n",
    "Must be all upper case. e.g. `\"GSE27562\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = \"GSE19804\"\n",
    "feature_size = 50\n",
    "alterStrat = AlterStrategy(AlterStrategy.GREEDY)\n",
    "estimator = Estimator(Estimator.NBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get/Create Directories\n",
    "Assumes this notebook is in `GenClass-Stability/main/notebooks/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = getcwd();\n",
    "main_dir = path.dirname(path.dirname(notebook_dir))\n",
    "load_path = path.join(main_dir, \"GSE\", series)\n",
    "gsa_path = path.join(main_dir,\"GSA\", series, str(feature_size))\n",
    "if not path.exists(gsa_path):\n",
    "    makedirs(gsa_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Classes and Expressions\n",
    "Load original data. Assumes SIT and custome GSE script have been run to import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =np.loadtxt(path.join(load_path, \"classes.txt\"), dtype=np.str, delimiter=\"\\t\")\n",
    "exprs = np.loadtxt(path.join(load_path, \"exprs.txt\"), delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select K best genes for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SelectKBestRanked(feature_size, exprs, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get selected genes from expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs = exprs[:, a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the selected expression data for potential later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path.join(gsa_path,\"exprs.npy\"), exprs)\n",
    "np.save(path.join(gsa_path,\"classses.npy\"), classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(alterStrat.getType() == AlterStrategy.GREEDY):\n",
    "    AlterStrategy.RankGreedy(estimator, exprs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: 0.0\n",
      "Accuracy: 0.97 (+/- 0.08)\n",
      "Percent: 0.05\n",
      "Accuracy: 0.94 (+/- 0.13)\n",
      "Percent: 0.1\n",
      "Accuracy: 0.93 (+/- 0.18)\n",
      "Percent: 0.15000000000000002\n",
      "Accuracy: 0.91 (+/- 0.20)\n",
      "Percent: 0.2\n",
      "Accuracy: 0.92 (+/- 0.15)\n",
      "Percent: 0.25\n",
      "Accuracy: 0.91 (+/- 0.22)\n",
      "Percent: 0.30000000000000004\n",
      "Accuracy: 0.93 (+/- 0.15)\n",
      "Percent: 0.35000000000000003\n",
      "Accuracy: 0.93 (+/- 0.16)\n",
      "Percent: 0.4\n",
      "Accuracy: 0.88 (+/- 0.17)\n",
      "Percent: 0.45\n",
      "Accuracy: 0.90 (+/- 0.26)\n",
      "Percent: 0.5\n",
      "Accuracy: 0.82 (+/- 0.19)\n",
      "Percent: 0.55\n",
      "Accuracy: 0.82 (+/- 0.28)\n",
      "Percent: 0.6000000000000001\n",
      "Accuracy: 0.76 (+/- 0.30)\n",
      "Percent: 0.65\n",
      "Accuracy: 0.74 (+/- 0.23)\n",
      "Percent: 0.7000000000000001\n",
      "Accuracy: 0.72 (+/- 0.39)\n",
      "Percent: 0.75\n",
      "Accuracy: 0.62 (+/- 0.25)\n",
      "Percent: 0.8\n",
      "Accuracy: 0.63 (+/- 0.27)\n",
      "Percent: 0.8500000000000001\n",
      "Accuracy: 0.61 (+/- 0.24)\n",
      "Percent: 0.9\n",
      "Accuracy: 0.52 (+/- 0.41)\n",
      "Percent: 0.9500000000000001\n",
      "Accuracy: 0.59 (+/- 0.24)\n",
      "Percent: 1.0\n",
      "Accuracy: 0.45 (+/- 0.24)\n"
     ]
    }
   ],
   "source": [
    "percents = np.arange(0,1.01,0.05)\n",
    "accuracies = []\n",
    "stds = []\n",
    "for percent in percents:\n",
    "    print (\"Percent:\", percent)\n",
    "    scores = crossValidate(estimator, exprs, classes, alterStrat, percent, 10)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    accuracies.append(scores.mean())\n",
    "    stds.append(scores.std())\n",
    "accuracies = np.array(accuracies)\n",
    "stds = np.array(stds)\n",
    "\n",
    "result = np.column_stack((percents,accuracies,stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = '{}_{}_result.npy'.format(estimator.getName(), alterStrat.getName())\n",
    "np.save(path.join(gsa_path, fileName), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.96666667 0.04082483]\n",
      " [0.05       0.94166667 0.06508541]\n",
      " [0.1        0.93333333 0.08975275]\n",
      " [0.15       0.90833333 0.1017213 ]\n",
      " [0.2        0.91666667 0.0745356 ]\n",
      " [0.25       0.90833333 0.10833333]\n",
      " [0.3        0.93333333 0.07264832]\n",
      " [0.35       0.925      0.07861651]\n",
      " [0.4        0.88333333 0.08498366]\n",
      " [0.45       0.9        0.1280191 ]\n",
      " [0.5        0.825      0.09464847]\n",
      " [0.55       0.81666667 0.13844373]\n",
      " [0.6        0.75833333 0.15115298]\n",
      " [0.65       0.74166667 0.11456439]\n",
      " [0.7        0.71666667 0.19436506]\n",
      " [0.75       0.625      0.125     ]\n",
      " [0.8        0.63333333 0.13540064]\n",
      " [0.85       0.60833333 0.11814539]\n",
      " [0.9        0.51666667 0.20682789]\n",
      " [0.95       0.59166667 0.1204736 ]\n",
      " [1.         0.45       0.11902381]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(zip(*list(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
