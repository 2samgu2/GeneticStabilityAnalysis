{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSA - Genetic Stability Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to speed up processing time when running classification algorithms, it is often useful to choose only the most \"best\" genes to use.  There are various algorithms available to choose genes, however here we use Chi2 Select K best.  K is how many genes you wish to use for testing stability.  More genese is usually better, however again in order to speed up processing time we limit the number of genes used.  This program allows you to set a min and max number of genes and an interval.  This will in turn setup numpy arrays with class and the select number of genes for further processing by FASTR and FASTrand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "Must be pre-installed.  Recommended to use virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terek/.virtualenvs/py370/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import sample, choice, uniform\n",
    "from os import path, getcwd, makedirs\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import Counter\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.sparse.linalg import lsqr\n",
    "from math import sqrt, floor\n",
    "from sklearn import svm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from enum import Enum\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and Classes\n",
    "This section defines all classes and methods used.  The corresponding methods and classes for each .py file found in `main/Python` are described here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NBC.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NBC.py file contains two classes: Model and NBC.  The Network-based supervised classification technique (NBC) is described in [Ahmet Ay et al](http://journals.sagepub.com/doi/abs/10.4137/CIN.S14025).  Briefly, for each gene, a model is constructed from the gene's neighbors.  The model is a function of the form:\n",
    "\n",
    "gene_expressipn @ g = neigh1X + neigh2X +....neighNx + C\n",
    "\n",
    "The set of expressions for all genes creates the expressio nmodel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\"The model constructed for a given class\"\"\"\n",
    "\n",
    "    def __init__(self, X, label, epsilon=0.8):\n",
    "        \"\"\"Initializes the model for a given class.\n",
    "\n",
    "        :param X: Training data for model. If array or matrix, shape [n_samples, n_features].\n",
    "        :param label: Class label for the data.\n",
    "        :param epsilon: epsilon value correlation cutoff\n",
    "        \"\"\"\n",
    "        self._label = label\n",
    "        self.X = np.array(X)\n",
    "\n",
    "        correlations = np.corrcoef(self.X, y=None, rowvar=False)\n",
    "\n",
    "        # Note: the mask is the graph.\n",
    "        self.mask = (np.absolute(correlations) > epsilon)\n",
    "\n",
    "        pool = Pool(processes=cpu_count())\n",
    "        self.coefficients = pool.map(self.solver, [gene for gene in range(len(correlations))])\n",
    "        pool.terminate()\n",
    "\n",
    "        self.coefficients = np.array(self.coefficients)\n",
    "\n",
    "    def solver(self, gene):\n",
    "        \"\"\"Uses least-square solver to compute coefficients for Ax=b, where\n",
    "        A is an equation list created from the neighbors of a gene and b is\n",
    "        the value of the gene.\n",
    "\n",
    "        :param gene: The index of the gene to be solved for.\n",
    "        :return: The coefficients of the equation (x) in Ax=b\n",
    "        \"\"\"\n",
    "        mask = self.mask[gene]\n",
    "        A = []\n",
    "        b = []\n",
    "        for sample in self.X:\n",
    "            neighbors = [sample[neighbor] if (mask[neighbor] and (gene != neighbor))\n",
    "                         else 0 for neighbor in range(len(mask))]\n",
    "            neighbors.append(1)\n",
    "            A.append(neighbors)\n",
    "            b.append(sample[gene])\n",
    "        A = np.array(A)\n",
    "        b = np.array(b)\n",
    "        x = lsqr(A, b)[0]\n",
    "        return x.tolist()\n",
    "\n",
    "    def expression(self, sample):\n",
    "        \"\"\"Returns a hypothetical expression level for a given sample.\n",
    "\n",
    "        :param sample: Test sample\n",
    "        :return: The hypothetical expression level of a given sample.\n",
    "        \"\"\"\n",
    "        expression = []\n",
    "        for gene in range(len(self.coefficients)):\n",
    "            level = 0  # the expression level of a gene\n",
    "            for neighbor in range(len(self.mask) - 1):\n",
    "                level += self.coefficients[gene][neighbor] * sample[neighbor]\n",
    "            level += self.coefficients[gene][len(self.mask)]\n",
    "            expression.append(level)\n",
    "        return np.array(expression)\n",
    "\n",
    "    def label(self):\n",
    "        \"\"\"Returns the class label of the model.\n",
    "\n",
    "        :return: The class label of the model.\n",
    "        \"\"\"\n",
    "        return self._label\n",
    "\n",
    "\n",
    "class NetworkBasedClassifier:\n",
    "    \"\"\"Classifier implementing the Network-based Classifier.\"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=0.8):\n",
    "        \"\"\"Initializes the classifier.\n",
    "\n",
    "        :param epsilon: epsilon value correlation cutoff.\n",
    "        \"\"\"\n",
    "        self.models = []\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the model using X as training data and y as target values.\n",
    "\n",
    "        :param X: Training data. If array or matrix, shape [n_samples, n_features].\n",
    "        :param y: Target values of shape = [n_samples]\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        X = np.array(X)\n",
    "        for label in Counter(y):\n",
    "            a_class = np.where(y == label)\n",
    "            self.models.append(Model([X[i] for i in a_class[0]], label, self.epsilon))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the class labels for the provided data.\n",
    "\n",
    "        :param X: Test samples.\n",
    "\n",
    "        :return: lass labels for each data sample.\n",
    "        \"\"\"\n",
    "        pool = Pool(processes=cpu_count())\n",
    "        classifications = pool.map(self.classification, [sample for sample in X])\n",
    "        pool.terminate()\n",
    "        return np.array(classifications)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Returns the mean accuracy on the given test data and labels.\n",
    "\n",
    "        :param X: Test samples.\n",
    "        :param y: True labels for X.\n",
    "\n",
    "        :return: Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        X = np.array(X)\n",
    "        correct = np.asarray(self.predict(X) == y)\n",
    "        return np.sum(correct) / correct.shape[0]\n",
    "\n",
    "    def classification(self, sample):\n",
    "        \"\"\"Returns the classification of the sample.\n",
    "\n",
    "        :param sample: Test sample\n",
    "        :return: The class label of the sample.\n",
    "        \"\"\"\n",
    "        errors = []\n",
    "        for model in self.models:\n",
    "            error = sqrt(mean_squared_error(sample, model.expression(sample)))\n",
    "            errors.append(error)\n",
    "        min_index = errors.index(min(errors))\n",
    "        return self.models[min_index].label()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alter.py\n",
    "The Alter.py file contains all methods and helper methods used to alter expressions.  There are currently four methods to alter expressions:\n",
    "\n",
    "1) Greedy - uses a greed strategy to select the top k genes that will produce the largest bad accuracy\n",
    "2) All - alters all genes by some percent amount.\n",
    "3) Subset - alters a subset of the genes selected via chi2 value\n",
    "4) RandSubset - alters a subset of the genes selected randomly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlterStrategy:\n",
    "    \"\"\"Describes the alteration strategy used.\"\"\"\n",
    "\n",
    "    # Alter strategies included:\n",
    "    ALL = 0\n",
    "    SUB = 1\n",
    "    RANDSUB = 2\n",
    "    GREEDY = 3\n",
    "    \n",
    "    def __init__(self,\n",
    "                 _type):\n",
    "        self._type = _type\n",
    "        if _type == AlterStrategy.ALL:\n",
    "            self._name = \"ALL\"\n",
    "        elif (_type == AlterStrategy.SUB):\n",
    "            self._name = \"SUB\"\n",
    "        elif (_type == AlterStrategy.RANDSUB):\n",
    "            self._name = \"RANDSUB\"\n",
    "        elif (_type == AlterStrategy.GREEDY):\n",
    "            self._name = \"GREEDY\"\n",
    "    \n",
    "    def getType(self):\n",
    "        return self._type\n",
    "    \n",
    "    def getName(self):\n",
    "        return self._name\n",
    "    \n",
    "    def Accuracy(estimator, X, y, chosen, idx_to_change):\n",
    "        # TODO: run multiple times and return avg accuracy\n",
    "        result = []\n",
    "        for x in X:\n",
    "            alt = np.copy(x)\n",
    "            # alter prev chosen\n",
    "            for i in chosen:\n",
    "                #alt[i] = choice([0, alt[i]*2]) \n",
    "                alt[i] = 0\n",
    "            # alter new gene\n",
    "            #alt[idx_to_change] = choice([0, alt[idx_to_change]*2]) \n",
    "            alt[idx_to_change] = 0\n",
    "            result.append(alt)\n",
    "        result = np.array(result)\n",
    "        return estimator.score(result, y)\n",
    "\n",
    "    '''Static method'''\n",
    "    def RankGreedy(estimator, X, y):\n",
    "        fileName = '{}greedyRank.npy'.format(estimator.getName())\n",
    "        if (path.exists(path.join(gsa_path, fileName))):\n",
    "            return\n",
    "        print(\"GREEDY RANK INITIALIZER - THIS CAN TAKE A WHILE.\")\n",
    "        estimator.fit(X,y)\n",
    "        notChosen = list(range(X.shape[1]))\n",
    "        chosen = []\n",
    "        for i in range(X.shape[1]):\n",
    "            pool = mp.Pool(processes = mp.cpu_count())\n",
    "            accuracy = pool.starmap(AlterStrategy.Accuracy, [(estimator, X, y, chosen, idx) for idx in notChosen])\n",
    "            pool.terminate()\n",
    "            a = [x for _,x in sorted(zip(accuracy, notChosen))]\n",
    "            chosen.append(a[0])\n",
    "            notChosen.remove(a[0])  \n",
    "        np.save(path.join(gsa_path,fileName), chosen)\n",
    "        \n",
    "    def Subset(percent, X):\n",
    "        \"\"\"\n",
    "        B/c genese are already ordered by chi2 rank we can choose top k to alter.\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        idx = floor(X[0].size * percent)\n",
    "        if idx <= 0:\n",
    "            return X\n",
    "        else:\n",
    "            for x in X:\n",
    "                alt = np.copy(x)\n",
    "                for i in range(idx):\n",
    "                    alt[i] = choice([0, alt[i]*2])\n",
    "                result.append(alt)\n",
    "            return np.array(result)\n",
    "\n",
    "    def RandSubset(percent,X):\n",
    "        result = []\n",
    "        k = floor(X[0].size * percent)\n",
    "        if k <= 0:\n",
    "            return X\n",
    "        else:\n",
    "            indices = sample(range(X[0].size),k)\n",
    "            for x in X:\n",
    "                alt = np.copy(x)\n",
    "                for i in indices:\n",
    "                    alt[i] = choice([0, alt[i]*2])\n",
    "                result.append(alt)\n",
    "            return np.array(result)\n",
    "        \n",
    "    def All(percent, X):\n",
    "        print(percent)\n",
    "        result = []\n",
    "        for x in X:\n",
    "            print(x)\n",
    "            alt = []\n",
    "            for gene in x:\n",
    "                _offset = gene * percent\n",
    "                _low = gene - _offset\n",
    "                _high = gene + _offset\n",
    "                alt.append(choice([_low,_high]))\n",
    "            result.append(alt)\n",
    "            print(alt)\n",
    "        return np.array(result)        \n",
    "        \n",
    "    def Greedy(percent, X, estimator):\n",
    "        high = np.amax(X)\n",
    "        low = np.amin(X)\n",
    "        result = []\n",
    "        k = floor(X[0].size * percent)\n",
    "        if k <= 0:\n",
    "            return X        \n",
    "        else:\n",
    "            file = path.join(gsa_path,'{}greedyRank.npy'.format(estimator.getName()))\n",
    "            indices = np.load(file)\n",
    "            for x in X:\n",
    "                alt = np.copy(x)\n",
    "                for i in indices[0:k:1]:\n",
    "                    alt[i] = uniform(low, high)\n",
    "                result.append(alt)\n",
    "            return np.array(result)        \n",
    "        \n",
    "    def Alter(self, percent, X, estimator):\n",
    "        if self._type == AlterStrategy.ALL:\n",
    "            return AlterStrategy.All(percent, X)\n",
    "        elif self._type == AlterStrategy.SUB:\n",
    "            return AlterStrategy.Subset(percent, X)\n",
    "        elif self._type == AlterStrategy.RANDSUB:\n",
    "            return AlterStrategy.RandSubset(percent, X)\n",
    "        elif self._type == AlterStrategy.GREEDY:\n",
    "            return AlterStrategy.Greedy(percent, X, estimator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy is to choose greedily, however because of the random choice from the Accuracy method strategy, different genese may be chose, thus affecting the order in which the rank returns.  In general, the top gene should be the top gene in all cases, but as it progresses the genese can switch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common.py\n",
    "These are files that are helpers for the main program.  They consist of two methods:\n",
    "1) A method to order the K best ranked genes.  This is used in conjunction with Atler.py Subset method.\n",
    "2) A method to cross validate.  This is different than normal cross validation in that the estimator is fit to correct data while the score is derived from altered data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SelectKBestRanked(k, X, y):    \n",
    "    b = SelectKBest(chi2, k).fit(X, y)\n",
    "    a = b.get_support(indices = True)\n",
    "    a = [x for _,x in sorted(zip(b.scores_[a],a),reverse=True)]\n",
    "    return np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidate(estimator, X, y, alterStrat, percent=0, cv=10):\n",
    "    scores = []\n",
    "    skf = StratifiedKFold(cv)\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        estimator.fit(X[train_index], y[train_index]) \n",
    "        accuracy = estimator.score(\n",
    "            alterStrat.Alter(percent, X[test_index],estimator),\n",
    "            y[test_index])\n",
    "        scores.append(accuracy)\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimatory.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator:\n",
    "    \"\"\"Describes the classifier chooser.\"\"\"\n",
    "\n",
    "    # Classifiers included in the chooser\n",
    "    NBC = 0\n",
    "    KNN = 1\n",
    "    SVM = 2\n",
    "    RF = 3\n",
    "    NB = 4\n",
    "    \n",
    "    def __init__(self,\n",
    "                 _type,\n",
    "                 epsilon=0.8,\n",
    "                 neighbors=1):\n",
    "        \"\"\"Initialize a NBF classifier.\n",
    "\n",
    "        Args:\n",
    "            eps: epsilon value\n",
    "        \"\"\"\n",
    "        self._type = _type\n",
    "\n",
    "        # create the classifier\n",
    "        if _type == Estimator.NBC:\n",
    "            self._classifier = NetworkBasedClassifier(epsilon)\n",
    "            self._name = \"NBC\"\n",
    "        elif (_type == Estimator.KNN):\n",
    "            self._classifier = KNeighborsClassifier(neighbors)\n",
    "            self._name = \"KNN\"\n",
    "        elif (_type == Estimator.SVM):\n",
    "            self._classifier = svm.LinearSVC()\n",
    "            self._name = \"SVM\"\n",
    "        elif (_type == Estimator.RF):\n",
    "            self._classifier = RandomForestClassifier()\n",
    "            self._name = \"RF\"\n",
    "        elif (_type == Estimator.NB):\n",
    "            self._classifier = GaussianNB()\n",
    "            self._name = \"NB\"\n",
    "    \n",
    "    def getType(self):\n",
    "        return self._type\n",
    "    \n",
    "    def getName(self):\n",
    "        return self._name\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._classifier.fit(X,y)\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return self._classifier.score(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self._classifier.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START MAIN PROGRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Enter the series and feature_size to use\n",
    "Must be all upper case. e.g. `\"GSE27562\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = \"GSE19804\"\n",
    "feature_size = 50\n",
    "alterStrat = AlterStrategy(AlterStrategy.RANDSUB)\n",
    "estimator = Estimator(Estimator.NBC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get/Create Directories\n",
    "Assumes this notebook is in `GenClass-Stability/main/notebooks/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = getcwd();\n",
    "main_dir = path.dirname(path.dirname(notebook_dir))\n",
    "load_path = path.join(main_dir, \"GSE\", series)\n",
    "gsa_path = path.join(main_dir,\"GSA\", series, str(feature_size))\n",
    "if not path.exists(gsa_path):\n",
    "    makedirs(gsa_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Classes and Expressions\n",
    "Load original data. Assumes SIT and custome GSE script have been run to import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =np.loadtxt(path.join(load_path, \"classes.txt\"), dtype=np.str, delimiter=\"\\t\")\n",
    "exprs = np.loadtxt(path.join(load_path, \"exprs.txt\"), delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select K best genes for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = SelectKBestRanked(feature_size, exprs, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get selected genes from expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs = exprs[:, a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the selected expression data for potential later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path.join(gsa_path,\"exprs.npy\"), exprs)\n",
    "np.save(path.join(gsa_path,\"classses.npy\"), classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stability Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(alterStrat.getType() == AlterStrategy.GREEDY):\n",
    "    AlterStrategy.RankGreedy(estimator, exprs, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: 0.0\n",
      "Accuracy: 0.97 (+/- 0.04)\n",
      "Percent: 0.05\n",
      "Accuracy: 0.97 (+/- 0.04)\n",
      "Percent: 0.1\n",
      "Accuracy: 0.90 (+/- 0.08)\n",
      "Percent: 0.15000000000000002\n",
      "Accuracy: 0.88 (+/- 0.11)\n",
      "Percent: 0.2\n",
      "Accuracy: 0.84 (+/- 0.16)\n",
      "Percent: 0.25\n",
      "Accuracy: 0.78 (+/- 0.09)\n",
      "Percent: 0.30000000000000004\n",
      "Accuracy: 0.79 (+/- 0.14)\n",
      "Percent: 0.35000000000000003\n",
      "Accuracy: 0.69 (+/- 0.15)\n",
      "Percent: 0.4\n",
      "Accuracy: 0.72 (+/- 0.13)\n",
      "Percent: 0.45\n",
      "Accuracy: 0.70 (+/- 0.18)\n",
      "Percent: 0.5\n",
      "Accuracy: 0.67 (+/- 0.10)\n",
      "Percent: 0.55\n",
      "Accuracy: 0.63 (+/- 0.12)\n",
      "Percent: 0.6000000000000001\n",
      "Accuracy: 0.60 (+/- 0.13)\n",
      "Percent: 0.65\n",
      "Accuracy: 0.62 (+/- 0.15)\n",
      "Percent: 0.7000000000000001\n",
      "Accuracy: 0.59 (+/- 0.10)\n",
      "Percent: 0.75\n",
      "Accuracy: 0.55 (+/- 0.17)\n",
      "Percent: 0.8\n",
      "Accuracy: 0.48 (+/- 0.13)\n",
      "Percent: 0.8500000000000001\n",
      "Accuracy: 0.60 (+/- 0.09)\n",
      "Percent: 0.9\n",
      "Accuracy: 0.53 (+/- 0.11)\n",
      "Percent: 0.9500000000000001\n",
      "Accuracy: 0.56 (+/- 0.16)\n",
      "Percent: 1.0\n",
      "Accuracy: 0.61 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "percents = np.arange(0,1.01,0.05)\n",
    "accuracies = []\n",
    "stds = []\n",
    "for percent in percents:\n",
    "    print (\"Percent:\", percent)\n",
    "    scores = crossValidate(estimator, exprs, classes, alterStrat, percent, 10)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "    accuracies.append(scores.mean())\n",
    "    stds.append(scores.std())\n",
    "accuracies = np.array(accuracies)\n",
    "stds = np.array(stds)\n",
    "\n",
    "result = np.column_stack((percents,accuracies,stds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName = '{}_{}_result.npy'.format(estimator.getName(), alterStrat.getName())\n",
    "np.save(path.join(gsa_path, fileName), result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.96666667 0.04082483]\n",
      " [0.05       0.96666667 0.04082483]\n",
      " [0.1        0.9        0.08164966]\n",
      " [0.15       0.875      0.11334559]\n",
      " [0.2        0.84166667 0.16007811]\n",
      " [0.25       0.78333333 0.09279607]\n",
      " [0.3        0.79166667 0.13565684]\n",
      " [0.35       0.69166667 0.14930394]\n",
      " [0.4        0.71666667 0.13017083]\n",
      " [0.45       0.7        0.17559423]\n",
      " [0.5        0.66666667 0.09860133]\n",
      " [0.55       0.63333333 0.11902381]\n",
      " [0.6        0.6        0.13333333]\n",
      " [0.65       0.61666667 0.15      ]\n",
      " [0.7        0.59166667 0.1017213 ]\n",
      " [0.75       0.55       0.16749793]\n",
      " [0.8        0.48333333 0.13333333]\n",
      " [0.85       0.6        0.08975275]\n",
      " [0.9        0.525      0.10573815]\n",
      " [0.95       0.55833333 0.15833333]\n",
      " [1.         0.60833333 0.12388391]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(zip(*list(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
